{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# PPG Pre-processing and SQI Calculations using Pandas on multiple Patients\n\nTrimming, Filtering, Segmentation and SQI Calculations utilising Pandas on Multiple Patients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Code Adapted from:\n# https://meta00.github.io/vital_sqi/_examples/others/plot_pipeline_02.html\n# AND\n# https://meta00.github.io/vital_sqi/_examples/others/plot_read_signal.html#sphx-glr-examples-others-plot-read-signal-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing Libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generic\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom datetime import datetime\nimport glob\n\n# Scipy\nfrom scipy.stats import skew, kurtosis, entropy\n\n # vitalSQI\nfrom vital_sqi.data.signal_io import PPG_reader\nimport vital_sqi.highlevel_functions.highlevel as sqi_hl\nimport vital_sqi.data.segment_split as sqi_sg\nfrom vital_sqi.common.rpeak_detection import PeakDetector\nfrom vital_sqi.preprocess.band_filter import BandpassFilter\nimport vital_sqi.sqi as sq\n\nfilepath_start = r'..\\..\\..\\..\\OUCRU\\01NVa_Dengue\\Adults'\nfilename_Clinical = r'..\\..\\..\\..\\OUCRU\\Clinical\\v0.0.10\\01nva_data_stacked_corrected.csv'\nfiles = os.listdir(filepath_start) # fetching the list of records (currently only 3 for processing simplicity)\n\n#Loading Clinical Data to a Dataframe\n\nClinical = pd.read_csv(filename_Clinical)\n\n#defining constants\ntrim_amount = 300\nhp_filt_params = (1, 1) #(Hz, order)\nlp_filt_params = (20, 4) #(Hz, order)\nfilter_type =  'butter'\nsegment_length = 30\nsampling_rate = 100\n\nTERMINAL = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Defining Functions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#find the start of PPG from clinical Data\ndef find_event_ppg_time(Clinical,Patient):\n    row = Clinical[(Clinical.study_no == Patient) & (Clinical.column == 'event_ppg') & (Clinical.result == 'True')]\n    return row['date'].values\n\n#======================================================\n\n# Band-pass filtering\n\n'''\nBand-pass filtering can be adjusted, maybe use a lower low-pass\ncutoff frequency @15-17Hz\n\n'''\n#Band pass filtering function\ndef bpf(signal):\n    hp_filt_params = (1, 1) #(Cutoff Hz, order)\n    lp_filt_params = (20, 4) #( Cutoff Hz, order)\n    sampling_rate = 100\n    filter = BandpassFilter(band_type='butter', fs=sampling_rate)\n    filtered_signal = filter.signal_highpass_filter(signal, cutoff=hp_filt_params[0], order=hp_filt_params[1])\n    filtered_signal = filter.signal_lowpass_filter(filtered_signal, cutoff=lp_filt_params[0], order=lp_filt_params[1])\n    return filtered_signal\n\n#======================================================\n\n# SQI Functions Definitions\n\ndef PeakDetection(x):\n    detector = PeakDetector()\n    peaks, troughs = detector.ppg_detector(x, 7) #6 and 7 work the best\n    return peaks, troughs\n\n#Defining SQI Functions\n\ndef snr(x):\n    #Signal to noise ratio\n    #needs raw signal\n    return np.mean(sq.standard_sqi.signal_to_noise_sqi(x))\n\ndef zcr(x):\n    #Zero Crossing Rate\n    #Needs filtered signal\n    return 0.5 * np.mean(np.abs(np.diff(np.sign(x))))\n\ndef mcr(x):\n    #Mean Crossing Rate\n    #needs raw signal\n    return zcr(x - np.mean(x))\n\ndef perfusion(x,y):\n    return (np.max(y) - np.min(y)) / np.abs(np.mean(x)) * 100\n\ndef correlogram(x):\n    #Correlogram\n    #Needs filtered signal\n    return sq.rpeaks_sqi.correlogram_sqi(x)\n\n'''\nMSQ values that are being calculated are too small, maybe peakdetectors need\nto be revisited?\n'''\ndef msq(x,peaks):\n    #Dynamic Time Warping\n    #Requires Filtered Signal and peaks\n     # Return\n     return sq.standard_sqi.msq_sqi(x, peaks_1=peaks, peak_detect2=6)\n\n'''\nBelow function is outputting an error, needs revisiting\n'''\n# def dtw(x,troughs):\n#     #Dynamic Time Warping\n#     #Requires Filtered Signal and troughs and template selection 0-3 (0-2 for PPG)\n#     # Per beat\n#     dtw_list = sq.standard_sqi.per_beat_sqi(sqi_func=sq.dtw_sqi, troughs=troughs, signal=x, taper=True, template_type=1)\n#     # Return mean and standard deviation\n#     return [np.mean(dtw_list), np.std(dtw_list)]\n\n#======================================================\n\n# Function Computing SQIs\n\ndef sqi_all(x,raw,filtered,peaks,troughs):\n    \n    #Computing  all SQIs using the functions above\n    \n    # Information\n    dinfo = {\n        'PPG_w_s': x.PPG_Datetime.iloc[0], #timedate window start\n        'PPG_w_f': x.PPG_Datetime.iloc[-1], #timedate window finish\n        'first': x.idx.iloc[0],\n        'last': x.idx.iloc[-1],\n        'skew': skew(x[raw]),\n        'entropy': entropy(x[raw]),\n        'kurtosis': kurtosis(x[raw]),\n        'snr': snr(x[raw]),\n        'mcr': mcr(x[raw]),\n        'zcr': zcr(x[filtered]),\n        'msq': msq(x[filtered],peaks),\n        'perfusion': perfusion(x[raw], x[filtered]),\n        'correlogram': correlogram(x[filtered]),\n        #'dtw': dtw(x[filtered],troughs)\n    }\n    '''\n    When using dtw an empty signal error is presented that\n    needs fixing, not sure why it does that\n    '''\n    # Return\n    return pd.Series(dinfo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loop calculating SQIs of multiple records and concatenating results into a single dataframe\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "'''\nLooking through the directories and creating the SQI Dataframe for all patients.\nWe first calculate each patients SQIs and the carry out the rejection process (latter not yet implementred).\nWe then concatenate the SQIs along with other descriptors into a single SQI file.\n'''\n\n#reading the studies and automatically parsing the files\nfor i in range(len(files)):\n    filepath_end = os.listdir(os.path.join(filepath_start,files[i],r'PPG'))\n    filename = os.path.join(filepath_start,files[i],r'PPG',filepath_end[0])\n    data = pd.read_csv(filename)\n    \n    if TERMINAL:\n        print(data)\n        #print(data.PLETH)\n        #print(data.IR_ADC)\n        #print(data.TIMESTAMP_MS)\n        #print(data.SPO2_PCT)\n\n    signals = data[[\"PLETH\", \"IR_ADC\"]]\n\n    if TERMINAL:\n        # In the future we will be using plotly, for better graphs but due to processing times \n        # that change hasn't been made yet\n        plot_range = np.arange(0,1000,1)\n        fig, ax = plt.subplots()\n        ax.plot(plot_range, signals.iloc[0:1000, 0])\n    \n    # Setting the indexes for the raw data - adopted from examples\n    pd.Timedelta.__str__ = lambda x: x._repr_base('all')\n    \n    # Include column with index\n    signals = signals.reset_index()\n\n    #creating the timedelta index using ms\n    signals['timedelta'] = pd.to_timedelta(data.TIMESTAMP_MS, unit='ms')\n\n    #fetching the PPG start date\n    PPG_start_date = find_event_ppg_time(Clinical, files[i][-8:])\n\n    #converting to datetime format\n    PPG_start_date = datetime.strptime(PPG_start_date[0], '%Y-%m-%d %H:%M:%S')\n\n    #creating the PPG Datetime column by taking the datetime and adding the timedeltas to it for each datapoint\n    signals['PPG_Datetime'] = pd.to_datetime(PPG_start_date)\n    signals['PPG_Datetime']+= pd.to_timedelta(signals.timedelta)\n\n    # Set the timedelta index (keep numeric index too)\n    signals = signals.set_index('timedelta')\n\n    # Rename column to avoid confusion\n    signals = signals.rename(columns={'index': 'idx'})\n\n    if TERMINAL:\n        print(\"\\n Raw Signals:\")\n        print(signals)\n\n        #Plotting\n        fig, axes = plt.subplots(nrows=2, ncols=1)\n        axes = axes.flatten()\n        signals.iloc[:,1].plot(ax=axes[0])\n        signals.iloc[:,2].plot(ax=axes[1])\n    \n    # Trimming the first and last 5 minutes\n\n    #Defining the 5 minute offset\n    offset = pd.Timedelta(minutes=5)\n\n    #Indexes - adopted from example\n    idxs = (signals.index > offset) & \\\n            (signals.index < signals.index[-1] - offset)\n\n    #Trimming\n    signals = signals[idxs]\n    \n    if TERMINAL:\n        print('\\n Truncated Signals:')\n        print(signals)\n    \n    \n    # RESAMPLE??\n    # MISSING DATA INPUT??\n    # TAPPERING??\n\n    #Band-pass filtered signals\n    signals['PLETH_bpf'] = bpf(signals.iloc[:,1])\n    signals['IR_ADC_bpf'] = bpf(signals.iloc[:,2])\n\n    if TERMINAL:\n        print('\\n Raw and Filtered Signals:')\n        print(signals)\n\n        fig, axes = plt.subplots(nrows=2, ncols=1)\n        axes = axes.flatten()\n        signals['PLETH_bpf'].plot(ax=axes[0])\n        signals['IR_ADC_bpf'].plot(ax=axes[1])\n\n    #Calculating peaks and troughs using peakdetector function for both filtered signals\n    peak_list_0, trough_list_0 = PeakDetection(signals['PLETH_bpf'])\n    peak_list_1, trough_list_1 = PeakDetection(signals['IR_ADC_bpf'])\n\n    # Calculating SQIs for both signals 0 = Pleth and 1 = IR_ADC using both filtered and unfiltered signals\n    sqis_0 = signals.groupby(pd.Grouper(freq='30s')).apply(lambda x: sqi_all(x, 'PLETH','PLETH_bpf', peak_list_0, trough_list_0))\n    sqis_1 = signals.groupby(pd.Grouper(freq='30s')).apply(lambda x: sqi_all(x, 'IR_ADC','IR_ADC_bpf', peak_list_1, trough_list_1))\n\n    #Displaying the SQIs per signal\n    print(\"SQIs Signal 0 (Pleth):\")\n    sqis_0\n    print(sqis_0)\n\n    print(\"SQIs Signal 1 (IR_ADC):\")\n    sqis_1\n    print(sqis_1)\n    #removing duplicates \n    sqis_1 = sqis_1.drop(['first','last', 'PPG_w_s', 'PPG_w_f'], axis = 1)\n\n    # Add window id to identify point of interest more easily\n    sqis_1['w'] = np.arange(sqis_1.shape[0])\n\n\n\n    #Final Formatting into a single DataFrame and Saving into a .csv file\n\n    #Merging SQIs of different signals from the same record (Pleth and IR_ADC) \n    Signal_SQIs = sqis_0.merge(sqis_1, on='timedelta', suffixes=('_0', '_1'))\n\n    #Automatically fetching the study_no from the filename and including it in the DataFrame\n    Signal_SQIs['study_no'] = files[i][-8:]\n\n    if TERMINAL:\n        print('\\n Individual SQI Check:')\n        print(Signal_SQIs)\n\n    '''\n\n    Discarding process to be added here.\n\n    '''\n\n    #concatenating into a single dataframe for all studies\n    if i == 0:\n        Complete_SQIs = Signal_SQIs\n    else:\n        Complete_SQIs = pd.concat([Complete_SQIs, Signal_SQIs])\n\n#Saving to csv format\nComplete_SQIs.to_csv(r'..\\..\\..\\..\\OUCRU\\Outputs\\Complete_SQIs.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SQI Requirements\nexample of the output\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img = plt.imread(r'..\\..\\..\\..\\MISC\\SQI_requirements.png')\nplt.title('SQI Requirements')  \nplt.imshow(img)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}